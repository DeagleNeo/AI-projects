{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b97f952",
   "metadata": {},
   "source": [
    "## 1. Create environment using conda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a626aa71",
   "metadata": {},
   "source": [
    "`# Setup conda environment`<br>\n",
    "`conda create -n tcm-ai-rag python=3.10`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c157456",
   "metadata": {},
   "source": [
    "`# Activate environment`<br>`conda activate tcm-ai-rag`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036ded07",
   "metadata": {},
   "source": [
    "## 2. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4ef496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install llama-index\n",
    "# !pip install llama-index-embeddings-huggingface\n",
    "# !pip install llama-index-llms-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b769cd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install CUDA-version Pytorch\n",
    "# !pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1 --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df21b71",
   "metadata": {},
   "source": [
    "## 3. Download models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe824eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install modelscope\n",
    "# !pip install modelscope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70d66d0",
   "metadata": {},
   "source": [
    "### 3.1 Download Embedding model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8532eb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use SDK from modelscope to download the model\n",
    "from modelscope import snapshot_download\n",
    "\n",
    "model_dir = snapshot_download(model_id=\"BAAI/bge-base-zh-v1.5\", cache_dir=\"D:/work/AIProject/modelscope\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03748f01",
   "metadata": {},
   "source": [
    "### 3.2 Download LLM weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128e5870",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelscope import snapshot_download\n",
    "\n",
    "model_dir = snapshot_download(model_id=\"Qwen/Qwen2.5-7B-Instruct\", cache_dir=\"D:/work/AIProject/modelscope\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c32a6a",
   "metadata": {},
   "source": [
    "## 4. Construct a Question-and-Answer System for Traditional Chinese Medicine Clinical Diagnosis and Treatment Terminology and Syndromes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e77095e",
   "metadata": {},
   "source": [
    "### 4.1 Corpus Preparation\n",
    "#### Please download the Traditional Chinese Medicine clinical diagnosis and treatment terminology materials issued by the National Health Commission and the National Administration of Traditional Chinese Medicine for the specific corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af32f328",
   "metadata": {},
   "source": [
    "#### **Partial Content Preview**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966f8bed",
   "metadata": {},
   "source": [
    "#### **气机阻滞证 syndrome/pattern of obstructed qi movement**<br>泛指因各种原因导致气机不畅，或气郁而不散，阻滞脏腑、经络、官窍等所引起的一类证候。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d06c05c",
   "metadata": {},
   "source": [
    "#### **气机郁滞证 syndrome/pattern of qi activity stagnation**<br>因气机郁结，阻滞经络或脏腑官窍所致。临床以头颈肩背或胸胁脘腹等处闷胀，或攻窜作痛，常随紧张、抑郁等情绪缓解，或得太息、嗳气、肠鸣、矢气而减轻，脉弦，可伴见大便时秘或泻，小便不利，耳鸣、耳聋，嘶哑、呃逆等为特征的证候。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a15bb41",
   "metadata": {},
   "source": [
    "#### **气滞耳窍证 syndrome/pattern of qi stagnation in the ears**<br>因肝气郁结，气机不利，气滞耳窍所致。临床以突然耳窍失聪，或耳内堵塞，耳鸣，眩晕，脉弦，伴见胸胁胀闷，情绪抑郁等为特征的证候。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f28eac",
   "metadata": {},
   "source": [
    "#### **气滞耳带证 syndrome/pattern of qi stagnation in the vocal fold**<br>因气机阻滞，痹阻声带所致。临床以声音不扬、嘶哑，言语费劲或磕巴，脉弦，可伴见咽喉不适，胸闷，胁胀等为特征的证候。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f473974",
   "metadata": {},
   "source": [
    "### 4.2 Rapid Knowledge Base Construction Based on LlamaIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba19d621",
   "metadata": {},
   "source": [
    "#### 4.2.1 Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212bee10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import torch\n",
    "from llama_index.core import PromptTemplate, Settings, SimpleDirectoryReader, VectorStoreIndex, load_index_from_storage, StorageContext\n",
    "from llama_index.core.schema import MetadataMode\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "from llama_index.core.node_parser import SentenceSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986515c5",
   "metadata": {},
   "source": [
    "#### 4.2.2 Configure logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5550e290",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d643fa85",
   "metadata": {},
   "source": [
    "#### 4.2.3 Construct System Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624061f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"You are a helpful AI assistant.\"\"\"\n",
    "query_wrapper_prompt = PromptTemplate(\n",
    "    \"[INST]<<SYS>>\\n\" + SYSTEM_PROMPT + \"<</SYS>>\\n\\n{query_str}[/INST]\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526d1068",
   "metadata": {},
   "source": [
    "#### 4.2.4 Load the downloaded Local LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba65393",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm = HuggingFaceLLM(\n",
    "    context_window=4096,\n",
    "    max_new_tokens=2048,\n",
    "    generate_kwargs={\"temperature\": 0.0, \"do_sample\": False},\n",
    "    query_wrapper_prompt=query_wrapper_prompt,\n",
    "    tokenizer_name='D:/work/AIProject/modelscope/Qwen/Qwen2___5-7B-Instruct',\n",
    "    model_name='D:/work/AIProject/modelscope/Qwen/Qwen2___5-7B-Instruct',\n",
    "    device_map=\"auto\",\n",
    "    model_kwargs={\"torch_dtype\": torch.float16}\n",
    ")\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d721ec",
   "metadata": {},
   "source": [
    "#### 4.2.5 Load the downloaded local embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b446a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name='./D:/work/AIProject/modelscope/BAAI/bge-base-zh-v1___5'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d000712",
   "metadata": {},
   "source": [
    "#### 4.2.6 Load the documents from the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918f98b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = SimpleDirectoryReader(\"./documents\", required_exts=[\".txt\"]).load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8631d0",
   "metadata": {},
   "source": [
    "#### 4.2.7 Build the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd049ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the documents and convert the texts into vectors using the embedding model\n",
    "index = VectorStoreIndex.from_documents(documents, transformations=[SentenceSplitter(chunk_size=256)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c07bbf",
   "metadata": {},
   "source": [
    "#### 4.2.8 Construct the query engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afece6b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(similarity_top_k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd68792e",
   "metadata": {},
   "source": [
    "#### 4.2.9 Generate the response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2aa426",
   "metadata": {},
   "source": [
    "response = query_engine.query(\"不耐疲劳，口渴、咽干可能是哪些证候？\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "958fa3f9",
   "metadata": {},
   "source": [
    "## 5. Vector storage and loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a42b924",
   "metadata": {},
   "source": [
    "### 5.1 Vector storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08db2326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the vector and vector index to storage\n",
    "index.storage_context.persist(persist_dir=\"doc_emb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ded41b8",
   "metadata": {},
   "source": [
    "In the persist_dir, there would be these json files:<br>- **default_vector_store.json**: Persist embedding vectors<br>- **docstore.json**: Persist splitted document segments (empty because of text documents used here)<br>- graph_store.json: Persist graph‑structured data (empty because of text documents used here)<br>- image__vector_store.json: Persist image data<br>- **index_store.json**: Persist vector indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b984045c",
   "metadata": {},
   "source": [
    "### 5.2 Vector loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf94115",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "# Load the vector and vector index from storage\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"doc_emb\")\n",
    "\n",
    "# Reconstruct the index\n",
    "index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf29383",
   "metadata": {},
   "source": [
    "## 6. Track retrieved document segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dbe882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the vector and vector index from storage\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"doc_emb\")\n",
    "\n",
    "# Reconstruct the index\n",
    "index = load_index_from_storage(storage_context)\n",
    "\n",
    "# Construct the query engine\n",
    "query_engine = index.as_query_engine(similarity_top_k=5)\n",
    "\n",
    "# Fetch the top 5 similar document segments\n",
    "contexts = query_engine.retrieve(QueryBundle(\"不耐疲劳，口燥、咽干可能是哪些证候？\"))\n",
    "print('-'*10 + 'ref' + '-'*10)\n",
    "for i, context in enumerate(contexts):\n",
    "   print('*'*10 + f'chunk {i} start' + '*'*10)\n",
    "   content = context.node.get_content(metadata_mode=MetadataMode.LLM)\n",
    "   print(content)\n",
    "   print('*' * 10 + f'chunk {i} end' + '*' * 10)\n",
    "print('-'*10 + 'ref' + '-'*10)\n",
    "\n",
    "# Generate the response\n",
    "response = query_engine.query(\"不耐疲劳，口燥、咽干可能是哪些证候？\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03fad66a",
   "metadata": {},
   "source": [
    "## 7. Underlying Implementation Details of RAG Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e6f0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import torch\n",
    "from llama_index.core import PromptTemplate, Settings, StorageContext, load_index_from_storage\n",
    "from llama_index.core.callbacks import LlamaDebugHandler, CallbackManager\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "# Construct system prompt\n",
    "SYSTEM_PROMPT = \"\"\"You are a helpful AI assistant.\"\"\"\n",
    "query_wrapper_prompt = PromptTemplate(\n",
    "    \"[INST]<<SYS>>\\n\" + SYSTEM_PROMPT + \"<</SYS>>\\n\\n{query_str}[/INST] \"\n",
    " )\n",
    "\n",
    "# Load the downloaded Local LLM\n",
    "llm = HuggingFaceLLM(\n",
    "    context_window=4096,\n",
    "    max_new_tokens=2048,\n",
    "    generate_kwargs={\"temperature\": 0.0, \"do_sample\": False},\n",
    "    query_wrapper_prompt=query_wrapper_prompt,\n",
    "    tokenizer_name='D:/AIProject/modelscope/Qwen/Qwen2___5-7B-Instruct',\n",
    "    model_name='D:/AIProject/modelscope/Qwen/Qwen2___5-7B-Instruct',\n",
    "    device_map=\"auto\",\n",
    "    model_kwargs={\"torch_dtype\": torch.float16},\n",
    " )\n",
    "Settings.llm = llm\n",
    "\n",
    "# Use LlamaDebugHandler to track LlamaIndex calls\n",
    "llama_debug = LlamaDebugHandler(print_trace_on_end=True)\n",
    "callback_manager = CallbackManager([llama_debug])\n",
    "Settings.callback_manager = callback_manager\n",
    "\n",
    "# Use llama-index-embeddings-huggingface to load the local embedding model\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "    model_name=\"D:/AIProject/modelscope/BAAI/bge-base-zh-v1___5\"\n",
    ")\n",
    "\n",
    "# Load the vector and vector index from storage\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"doc_emb\")\n",
    "index = load_index_from_storage(storage_context)\n",
    "\n",
    "# Construct the query engine\n",
    "query_engine = index.as_query_engine(similarity_top_k=5)\n",
    "\n",
    "# Generate the response\n",
    "response = query_engine.query(\"不耐疲劳，口燥、咽干可能是哪些证候？\")\n",
    "print(response)\n",
    "\n",
    "# return the start and end events of each LLM call\n",
    "event_pairs = llama_debug.get_llm_inputs_outputs()\n",
    "# print(event_pairs[0][1].payload.keys())\n",
    "print(event_pairs[0][1].payload[\"formatted_prompt\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cabf7a",
   "metadata": {},
   "source": [
    "## 8. Implement a simplified Chinese prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d661a09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "import torch\n",
    "from llama_index.core import PromptTemplate, Settings, StorageContext, load_index_from_storage\n",
    "from llama_index.core.callbacks import LlamaDebugHandler, CallbackManager\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.huggingface import HuggingFaceLLM\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))\n",
    "\n",
    "# Construct system prompt\n",
    "SYSTEM_PROMPT = \"\"\"你是一个医疗人工智能助手。\"\"\"\n",
    "query_wrapper_prompt = PromptTemplate(\n",
    "   \"[INST]<<SYS>>\\n\" + SYSTEM_PROMPT + \"<</SYS>>\\n\\n{query_str}[/INST] \"\n",
    ")\n",
    "\n",
    "# Construct Q&A prompt\n",
    "qa_prompt_tmpl_str = (\n",
    "    \"上下文信息如下。\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"请根据上下文信息而不是先验知识来回答以下的查询。\"\n",
    "    \"作为一个医疗人工智能助手，你的回答要尽可能严谨。\\n\"\n",
    "    \"Query: {query_str}\\n\"\n",
    "    \"Answer: \"\n",
    ")\n",
    "qa_prompt_tmpl = PromptTemplate(qa_prompt_tmpl_str)\n",
    "\n",
    "# Construct refine prompt\n",
    "refine_prompt_tmpl_str = (\n",
    "   \"原始查询如下：{query_str}\"\n",
    "   \"我们提供了现有答案：{existing_answer}\"\n",
    "   \"我们有机会通过下面的更多上下文来完善现有答案（仅在需要时）。\"\n",
    "   \"------------\"\n",
    "   \"{context_msg}\"\n",
    "   \"------------\"\n",
    "   \"考虑到新的上下文，优化原始答案以更好地回答查询。 如果上下文没有用，请返回原始答案。\"\n",
    "   \"Refined Answer:\"\n",
    ")\n",
    "refine_prompt_tmpl = PromptTemplate(refine_prompt_tmpl_str)\n",
    "\n",
    "# # Load the downloaded Local LLM\n",
    "llm = HuggingFaceLLM(\n",
    "   context_window=4096,\n",
    "   max_new_tokens=2048,\n",
    "   generate_kwargs={\"temperature\": 0.0, \"do_sample\": False},\n",
    "   query_wrapper_prompt=query_wrapper_prompt,\n",
    "   tokenizer_name='D:/AIProject/modelscope/Qwen/Qwen2___5-7B-Instruct',\n",
    "   model_name='D:/AIProject/modelscope/Qwen/Qwen2___5-7B-Instruct',\n",
    "   device_map=\"auto\",\n",
    "   model_kwargs={\"torch_dtype\": torch.float16},\n",
    ")\n",
    "Settings.llm = llm\n",
    "\n",
    "# Use LlamaDebugHandler to track LlamaIndex calls\n",
    "llama_debug = LlamaDebugHandler(print_trace_on_end=True)\n",
    "callback_manager = CallbackManager([llama_debug])\n",
    "Settings.callback_manager = callback_manager\n",
    "\n",
    "# Use llama-index-embeddings-huggingface to load the local embedding model\n",
    "Settings.embed_model = HuggingFaceEmbedding(\n",
    "   model_name=\"D:/AIProject/modelscope/BAAI/bge-base-zh-v1___5\"\n",
    ")\n",
    "\n",
    "# Load the vector and vector index from storage\n",
    "storage_context = StorageContext.from_defaults(persist_dir=\"doc_emb\")\n",
    "index = load_index_from_storage(storage_context)\n",
    "\n",
    "# Construct the query engine\n",
    "query_engine = index.as_query_engine(similarity_top_k=5)\n",
    "\n",
    "# Print all available prompt types in the query engine\n",
    "prompts_dict = query_engine.get_prompts()\n",
    "print(list(prompts_dict.keys()))\n",
    "\n",
    "# Update the query engine with the customized prompt templates\n",
    "query_engine.update_prompts(\n",
    "   {\"response_synthesizer:text_qa_template\": qa_prompt_tmpl,\n",
    "    \"response_synthesizer:refine_template\": refine_prompt_tmpl}\n",
    ")\n",
    "\n",
    "# Generate the response\n",
    "response = query_engine.query(\"不耐疲劳，口燥、咽干可能是哪些证候？\")\n",
    "print(response)\n",
    "\n",
    "# Print formatted_prompt\n",
    "event_pairs = llama_debug.get_llm_inputs_outputs()\n",
    "print(event_pairs[0][1].payload[\"formatted_prompt\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
